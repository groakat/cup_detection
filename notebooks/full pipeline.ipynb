{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import `cup_detection` modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from cup_detection.ml import training as T\n",
    "from cup_detection.ml import cardboard as MLCB\n",
    "from cup_detection.ml import cup as MLC\n",
    "from cup_detection.eye_tracker import render_distances as RD\n",
    "\n",
    "from cup_detection.io import image_sequence as IS\n",
    "\n",
    "import time\n",
    "import os\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load pretrained classifiers. \n",
    "\n",
    "This function returns a dictionary with the keys `card-board` for the cardboard classifier and `cups` for the cups detection classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "t1 = time.time()\n",
    "clfrs = T.load_all_classifiers(\"/Volumes/Seagate_Backup_Plus_Drive_black/datasets/cups/script_output/saved_classifiers\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set filename of input video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "video_filename = \"/Volumes/Seagate Backup Plus Drive/datasets/cups/vt_encoded/CORIA/Scan Path_table (17)_table-23-recording/Scan Path_table (17)_table-23-recording_full.mp4\"\n",
    "video_folder = \"/Volumes/Seagate_Backup_Plus_Drive_black/datasets/cups/image_sequences/CORIA/Scan Path_table (17)_table-23-recording\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "IS.video_to_image_sequence(video_file, video_folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classify each frame of the video as cardboard or not.\n",
    "\n",
    "The result is a dictionary with the keys:\n",
    "\n",
    "* `raw`: with the frame-wise classification results (boolean `np.array` with `1` for frames with cardboard and `0` for frames without)\n",
    "* `smooth`: with the frame-wise classification results after applying the smoothing function which removes spurious noise in the classification result in `raw`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "t2 = time.time()\n",
    "card_board_frames = MLCB.get_card_board_frames_from_video(video_folder, clfrs['card-board'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Locate the blue cup in frames without cardboard\n",
    "This function returns a pandas dataframe with the columns\n",
    "\n",
    "* `Frame`: framenumber of event\n",
    "* `cup x`: x coordinate\n",
    "* `cup y`: y coordinate\n",
    "\n",
    "with the argument `verbose=True` the function plots the current framenumber after each 100 frames the function iterated through"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "800\n",
      "900\n",
      "1000\n",
      "1100\n",
      "1200\n",
      "1300\n",
      "1400\n",
      "1500\n",
      "1600\n",
      "1700\n",
      "1800\n",
      "1900\n",
      "2000\n",
      "2100\n",
      "2200\n",
      "2300\n",
      "2400\n",
      "2500\n",
      "2600\n",
      "2700\n",
      "2800\n",
      "2900\n",
      "3000\n",
      "3100\n",
      "3200\n",
      "3300\n",
      "3400\n",
      "3500\n",
      "3600\n",
      "3700\n",
      "3800\n",
      "3900\n",
      "4000\n",
      "4100\n",
      "4200\n",
      "4300\n",
      "4400\n",
      "4500\n",
      "4600\n",
      "4700\n",
      "4800\n",
      "4900\n",
      "5000\n",
      "5100\n",
      "5200\n",
      "5300\n",
      "5400\n"
     ]
    }
   ],
   "source": [
    "t3 = time.time()\n",
    "cl_df = MLC.cup_predictions_outside_cardboard(video_folder, clfrs['cups'], \n",
    "                                              card_board_frames['smooth'],\n",
    "                                              verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save cup locations if necessary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "out_folder = \".\"\n",
    "cl_df.to_csv(os.path.join(out_folder, \"cup_locs.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "out_folder = \".\"\n",
    "cl_df = pd.read_csv(os.path.join(out_folder, \"cup_locs.csv\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## plot cup locations and eyetracker locations into frames\n",
    "\n",
    "First load the eye-tracker data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "et_filename = \"/Volumes/Seagate_Backup_Plus_Drive_black/datasets/cups/events/CORIA/SWTS2 20150312 CORIA_table (17)_023_Trial001 Samples.txt\"\n",
    "et_df = RD.load_eye_tracker_data(et_filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "call the plotting function with eye-tracker data and cup-locations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "t4 = time.time()\n",
    "out_folder = \"/Volumes/Seagate_Backup_Plus_Drive_black/datasets/cups/script_output/frames_out_pipeline_test3\"\n",
    "RD.tracking_on_video(video_folder, et_df, cl_df, out_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "t5 = time.time()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Render the plots into video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "out_video = os.path.join(out_folder, \"video.mp4\")\n",
    "IS.image_sequence_to_video(out_folder, out_video)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Approximate timings for a 3:48min video"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It takes about \n",
    "\n",
    "* 1h7min to detect card-board frames\n",
    "* 13min to get cup locations\n",
    "* 1h17min to plot the result on video frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.224729450544 87.6137160977 1118.02125085 148.668739518\n"
     ]
    }
   ],
   "source": [
    "print \"{} {} {} {}\".format((t2 - t1) / 60, (t3 - t2) / 60, (t4 - t3) / 60, (t5- t4) / 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## convert frames into video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from subprocess import call\n",
    "call([\"ffmpeg\", \"-r 24\", \"-i {}/frame_%04d.png\".format(out_folder),\n",
    "      \"-r 24\", \"-pix_fmt yuv420p\", \"{}/video.mp4\".format(out_folder)], shell=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "call([\"ls\", \"-l\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "call([\"ffmpeg\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "256"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.system(\"ffmpeg -r 24 -i {bf}/frame_%04d.png -r 24 -pix_fmt yuv420p {bf}/video.mp4\".format(bf=out_folder))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
